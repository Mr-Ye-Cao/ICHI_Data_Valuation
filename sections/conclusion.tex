\section{Conclusion}

This work initiates a study on the self-awareness of LLMs in the context of weight quantization. We propose a probing methodology that combines arithmetic reasoning with introspective querying to assess whether compressed LLMs can identify their own compression state. Our results show that several models can infer their quantized status with notable accuracy, especially when guided by in-context examples. These findings point toward the feasibility of embedding introspection capabilities in future development and have implications for building more interpretable AI systems.

% \section{Acknowledgment}
% The work of Zhaozhuo Xu was supported by NSF grants 2451398 and 2450524. 






